{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "def weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.data.normal_(0.0, 1e-3)\n",
    "        m.bias.data.fill_(0.)\n",
    "\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "[128, 512, 512, 512, 512]\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------\n",
    "# Device configuration\n",
    "#--------------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device: %s'%device)\n",
    "\n",
    "#--------------------------------\n",
    "# Hyper-parameters\n",
    "#--------------------------------\n",
    "input_size = 3\n",
    "num_classes = 10\n",
    "hidden_size = [128, 512, 512, 512, 512]\n",
    "num_epochs = 50 #20\n",
    "batch_size = 200\n",
    "learning_rate = 2e-3\n",
    "learning_rate_decay = 0.95\n",
    "reg=0.001\n",
    "num_training= 49000\n",
    "num_validation =1000\n",
    "norm_layer = None #norm_layer = 'BN'\n",
    "print(hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------\n",
    "# Load the CIFAR-10 dataset\n",
    "#-------------------------------------------------\n",
    "#################################################################################\n",
    "# TODO: Q3.a Choose the right data augmentation transforms with the right       #\n",
    "# hyper-parameters and put them in the data_aug_transforms variable             #\n",
    "#################################################################################\n",
    "data_aug_transforms = []\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "\n",
    "data_aug_transforms.append(torchvision.transforms.RandomCrop(size=25))\n",
    "data_aug_transforms.append(torchvision.transforms.ColorJitter(brightness=(0.3,0.7),contrast=(0.4,0.6)))\n",
    "data_aug_transforms.append(torchvision.transforms.RandomGrayscale(p=0.2))\n",
    "data_aug_transforms.append(torchvision.transforms.RandomAffine(degrees=(10,50),translate=(0.1,0.4),scale=(0.1,0.5)))\n",
    "\n",
    "                           \n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "norm_transform = transforms.Compose(data_aug_transforms+[transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                     ])\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                     ])\n",
    "cifar_dataset = torchvision.datasets.CIFAR10(root='datasets/',\n",
    "                                           train=True,\n",
    "                                           transform=norm_transform,\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='datasets/',\n",
    "                                          train=False,\n",
    "                                          transform=test_transform\n",
    "                                          )\n",
    "\n",
    "#-------------------------------------------------\n",
    "# Prepare the training and validation splits\n",
    "#-------------------------------------------------\n",
    "mask = list(range(num_training))\n",
    "train_dataset = torch.utils.data.Subset(cifar_dataset, mask)\n",
    "mask = list(range(num_training, num_training + num_validation))\n",
    "val_dataset = torch.utils.data.Subset(cifar_dataset, mask)\n",
    "\n",
    "#-------------------------------------------------\n",
    "# Data loader\n",
    "#-------------------------------------------------\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# Convolutional neural network (Q1.a and Q2.a)\n",
    "# Set norm_layer for different networks whether using batch normalization\n",
    "#-------------------------------------------------\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, num_classes, norm_layer=None):\n",
    "        super(ConvNet, self).__init__()\n",
    "        #################################################################################\n",
    "        # TODO: Initialize the modules required to implement the convolutional layer    #\n",
    "        # described in the exercise.                                                    #\n",
    "        # For Q1.a make use of conv2d and relu layers from the torch.nn module.         #\n",
    "        # For Q2.a make use of BatchNorm2d layer from the torch.nn module.              #\n",
    "        # For Q3.b Use Dropout layer from the torch.nn module.                          #\n",
    "        #################################################################################\n",
    "        layers = []\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        layers_dict = collections.OrderedDict()\n",
    "\n",
    "        # input block 1\n",
    "        layers_dict['conv_1'] = nn.Conv2d(input_size, hidden_layers[0],\\\n",
    "                                      kernel_size=3, stride=1, padding=1,bias=True)\n",
    "        if norm_layer=='BN':\n",
    "            layers_dict['batch_norm1']=nn.BatchNorm2d(hidden_layers[0])\n",
    "        layers_dict['maxpool_1'] = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        layers_dict['act_1'] = nn.ReLU(inplace=True)\n",
    "        # convolutional blocks 2-5\n",
    "        for i in range(1,len(hidden_layers)):\n",
    "            layers_dict['conv_'+str(i+1)] = \\\n",
    "            nn.Conv2d(hidden_layers[i-1], hidden_layers[i], kernel_size=3, stride=1, padding=1,bias=True)\n",
    "            if norm_layer=='BN':\n",
    "                layers_dict['batch_norm'+str(i+1)]=nn.BatchNorm2d(hidden_layers[i])\n",
    "            layers_dict['maxpool_'+str(i+1)] = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            layers_dict['act_'+str(i+1)] = nn.ReLU(inplace=True)\n",
    "\n",
    "        layers_dict['conv_flat'] = nn.Flatten() \n",
    "        layers_dict['lin_output'] = nn.Linear(hidden_layers[-1], num_classes, bias=True)\n",
    "\n",
    "        layers = list(layers_dict.values())\n",
    "        #print(layers)\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    def forward(self, x):\n",
    "        #################################################################################\n",
    "        # TODO: Implement the forward pass computations                                 #\n",
    "        #################################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        out = self.layers(x)\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# Calculate the model size (Q1.b)\n",
    "# if disp is true, print the model parameters, otherwise, only return the number of parameters.\n",
    "#-------------------------------------------------\n",
    "def PrintModelSize(model, disp=True):\n",
    "    #################################################################################\n",
    "    # TODO: Implement the function to count the number of trainable parameters in   #\n",
    "    # the input model. This useful to track the capacity of the model you are       #\n",
    "    # training                                                                      #\n",
    "    #################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "\n",
    "    model_sz=sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    if disp==True:\n",
    "        print('total number of parameters of the network is: '+str(model_sz))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    return model_sz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------\n",
    "# Calculate the model size (Q1.c)\n",
    "# visualize the convolution filters of the first convolution layer of the input model\n",
    "#-------------------------------------------------\n",
    "def VisualizeFilter(model):\n",
    "    #################################################################################\n",
    "    # TODO: Implement the functiont to visualize the weights in the first conv layer#\n",
    "    # in the model. Visualize them as a single image of stacked filters.            #\n",
    "    # You can use matlplotlib.imshow to visualize an image in python                #\n",
    "    #################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    pass\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): Flatten()\n",
      "    (16): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "total number of parameters of the network is: 7678474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7678474"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#======================================================================================\n",
    "# Q1.a: Implementing convolutional neural net in PyTorch\n",
    "#======================================================================================\n",
    "# In this question we will implement a convolutional neural networks using the PyTorch\n",
    "# library.  Please complete the code for the ConvNet class evaluating the model\n",
    "#--------------------------------------------------------------------------------------\n",
    "model = ConvNet(input_size, hidden_size, num_classes, norm_layer=norm_layer).to(device)\n",
    "# Q2.a - Initialize the model with correct batch norm layer\n",
    "\n",
    "model.apply(weights_init)\n",
    "# Print the model\n",
    "print(model)\n",
    "# Print model size\n",
    "#======================================================================================\n",
    "# Q1.b: Implementing the function to count the number of trainable parameters in the model\n",
    "#======================================================================================\n",
    "PrintModelSize(model)\n",
    "#======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x4320 with 128 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "old_level = logger.level\n",
    "logger.setLevel(100)\n",
    "\n",
    "# plotting code here,it will give multiple logs that its clipping input data to [0,255]to match RGB pictures\n",
    "fig = plt.figure(figsize=(30, 60),facecolor='black')\n",
    "\n",
    "for n,layer in enumerate(model.layers):\n",
    "    if n==0:\n",
    "        layer_weights= layer.weight.data.cpu().numpy()\n",
    "        for number,i in enumerate(layer_weights):\n",
    "            fig.add_subplot(8,16,number+1)\n",
    "            #fig.yticks([0,10,20,30,40,50,60])\n",
    "\n",
    "            plt.imshow(i)\n",
    "            plt.axis('off')\n",
    "            plt.axis(\"tight\")\n",
    "            #plt.axis(\"image\") \n",
    "            \n",
    "        fig.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "        plt.show()\n",
    "\n",
    "logger.setLevel(old_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Flatten()\n",
      "    (21): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "total number of parameters of the network is: 7682826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7682826"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#======================================================================================\n",
    "# Q2.a: Implementing convolutional neural net in PyTorch\n",
    "#======================================================================================\n",
    "# In this question we will implement a convolutional neural networks using the PyTorch\n",
    "# library.  Please complete the code for the ConvNet class evaluating the model\n",
    "#--------------------------------------------------------------------------------------\n",
    "model = ConvNet(input_size, hidden_size, num_classes, norm_layer='BN').to(device)\n",
    "# Q2.a - Initialize the model with correct batch norm layer\n",
    "\n",
    "model.apply(weights_init)\n",
    "# Print the model\n",
    "print(model)\n",
    "# Print model size\n",
    "#======================================================================================\n",
    "# Q1.b: Implementing the function to count the number of trainable parameters in the model\n",
    "#======================================================================================\n",
    "PrintModelSize(model)\n",
    "#======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (512x1x1). Calculated output size: (512x0x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9d225d66ca3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-fc58bff74071>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m#################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;31m# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;31m# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0;32m    140\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                             self.return_indices)\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m     return torch.max_pool2d(\n\u001b[1;32m--> 488\u001b[1;33m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m max_pool2d = boolean_dispatch(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (512x1x1). Calculated output size: (512x0x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "\n",
    "# Train the model\n",
    "lr = learning_rate\n",
    "total_step = len(train_loader)\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "best_accuracy = None\n",
    "accuracy_val = []\n",
    "#best_model = type(model)(input_size, hidden_size, num_classes, norm_layer=norm_layer) # get a new instance\n",
    "#best_model = ConvNet(input_size, hidden_size, num_classes, norm_layer=norm_layer)\n",
    "\n",
    "not_improving_epochs=0 # i guesss i can put this line here,for the early stopping part of the code,right??\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_iter = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_iter += loss.item()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            \n",
    "    loss_train.append(loss_iter/(len(train_loader)*batch_size))\n",
    "\n",
    "    \n",
    "    # Code to update the lr\n",
    "    lr *= learning_rate_decay\n",
    "    update_lr(optimizer, lr)\n",
    "    \n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loss_iter = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_iter += loss.item()\n",
    "        \n",
    "        loss_val.append(loss_iter/(len(val_loader)*batch_size))\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        accuracy_val.append(accuracy)\n",
    "        print('Validation accuracy is: {} %'.format(accuracy))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #################################################################################\n",
    "#################################################################################\n",
    "        # TODO: Q2.b Implement the early stopping mechanism to save the model which has #\n",
    "        # the model with the best validation accuracy so-far (use best_model).          #\n",
    "        #################################################################################\n",
    "\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        patience=4\n",
    "        early_stop=False\n",
    "\n",
    "        if epoch>patience-1:\n",
    "            for j in range(patience-1):\n",
    "                if max(accuracy_val)>list(reversed(accuracy_val))[j]:\n",
    "                    not_improving_epochs+=1\n",
    "                    print('validation accuracy didnt improve at epoch: '+str(epoch+1))\n",
    "                else:\n",
    "                    not_improving_epochs=0\n",
    "                    break\n",
    "                if not_improving_epochs>=patience:\n",
    "                    early_stop=True\n",
    "                    print('early stopping clause activated')\n",
    "                    break\n",
    "                break\n",
    "        if early_stop==True:\n",
    "            print('about to stop')\n",
    "            break\n",
    "       \n",
    "\n",
    "        \n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(loss_train, 'r', label='Train loss')\n",
    "plt.plot(loss_val, 'g', label='Val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.plot(accuracy_val, 'r', label='Val accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
